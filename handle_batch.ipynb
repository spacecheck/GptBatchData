{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import AzureOpenAI\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('key.txt', 'r') as file:\n",
    "    key = file.read().replace('\\n', '')\n",
    "\n",
    "with open('endpoint.txt', 'r') as file:\n",
    "    endpoint = file.read().replace('\\n', '')\n",
    "\n",
    "client = AzureOpenAI(api_key=key,\n",
    "                     api_version=\"2024-10-21\",\n",
    "                        azure_endpoint=endpoint)\n",
    "del key, endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_upload = os.listdir(\"files_jsonl/\")\n",
    "batch_input_files = []\n",
    "for file in files_to_upload:\n",
    "    if file.endswith(\".jsonl\"):\n",
    "        print(f\"Uploading {file}...\")\n",
    "        file_name = f\"files_jsonl/{file}\"\n",
    "        batch_input_file = client.files.create(\n",
    "            file = open(file_name, 'rb'),\n",
    "            purpose = \"batch\"\n",
    "        )\n",
    "        batch_input_files.append(batch_input_file)\n",
    "\n",
    "# save those ids for later use\n",
    "input_file_ids = [file.id for file in batch_input_files]\n",
    "print(input_file_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_objects = []\n",
    "\n",
    "for file, id in zip(files_to_upload, [file.id for file in batch_input_files]):\n",
    "    batch_object = client.batches.create(\n",
    "        input_file_id = id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\",\n",
    "        metadata={\"description\": file},\n",
    "    )\n",
    "    batch_objects.append(batch_object)\n",
    "\n",
    "# save those ids for later use\n",
    "batch_ids = [batch_object.id for batch_object in batch_objects]\n",
    "print(batch_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wait a couple seconds before checking the status of the batch jobs\n",
    "# batch_ids = ...\n",
    "\n",
    "status_objects = []\n",
    "# check the status of the batch jobs\n",
    "for id in batch_ids:\n",
    "    status_object = client.batches.retrieve(id)\n",
    "    status_objects.append(status_object)\n",
    "    print(status_object.status)\n",
    "# they go from \"validating\" to \"in_progress\" to \"completed\" or \"failed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if they are completed, we can download the results\n",
    "file_responses = []\n",
    "output_file_ids = []\n",
    "for status_object in status_objects:\n",
    "    response = client.files.content(status_object.output_file_id)\n",
    "    file_responses.append(response)\n",
    "    output_file_ids.append(status_object.output_file_id)\n",
    "\n",
    "# save those ids for later use\n",
    "print(output_file_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lines = []\n",
    "for response in file_responses:\n",
    "    lines = response.text.splitlines()\n",
    "    all_lines.extend(lines)\n",
    "all_jsons = [json.loads(line) for line in all_lines if line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0167 USD\n"
     ]
    }
   ],
   "source": [
    "#check the damage\n",
    "\n",
    "cost = 0\n",
    "output_lengths = []\n",
    "for json_message in all_jsons:\n",
    "    usage = json_message['response']['body']['usage']\n",
    "    prompt_tokens = usage['prompt_tokens']\n",
    "    completion_tokens = usage['completion_tokens']\n",
    "    cached_tokens = usage['prompt_tokens_details']['cached_tokens']\n",
    "    output_lengths.append(usage['completion_tokens'])\n",
    "    cost += (completion_tokens / 1000 * 0.005 + prompt_tokens / 1000 * 0.00125)\n",
    "print(f\"{cost:.4f} USD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "print(max(output_lengths)) # if you have a max output lenght equal to the set max output length, you should check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "issue_cases = [i for i in range(len(all_jsons)) if all_jsons[i][\"response\"][\"body\"][\"choices\"][0][\"finish_reason\"] != \"stop\"]\n",
    "print(issue_cases)\n",
    "print(\"\\n\")\n",
    "\n",
    "# print ids of issue cases\n",
    "issue_ids = [all_jsons[idx]['custom_id'] for idx in issue_cases]\n",
    "for idx in issue_cases:\n",
    "    print(all_jsons[idx]['custom_id'],\":\", all_jsons[idx]['response']['body']['choices'][0]['finish_reason'])\n",
    "\n",
    "if len(issue_ids) == 0:\n",
    "    pass\n",
    "else:\n",
    "    # append id to issue cases txt\n",
    "    with open(\"issue_cases.txt\", \"a\") as file:\n",
    "        for idx in issue_ids:\n",
    "            file.write(idx + \"\\n\")\n",
    "\n",
    "# if there are no issue cases then congratulate yourself\n",
    "# if there are you need to eather rerun them or discard them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_parser(json_content):\n",
    "    id_str = json_content[\"custom_id\"]\n",
    "    content_str = json_content[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "    return id_str, content_str\n",
    "\n",
    "all_info = [simple_parser(json_content) for json_content in all_jsons if json_content[\"custom_id\"] not in issue_ids]\n",
    "out_df = pd.DataFrame(all_info, columns=[\"id\", \"content\"])\n",
    "out_df.to_csv(\"output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"pretentious_recipy_name\": \"Ethereal Cloud of Passion\",\n",
      "    \"is_vegan\": false,\n",
      "    \"oven_instructions\": {\n",
      "        \"preheat_temperature_celcius\": 205,\n",
      "        \"time_in_oven_minutes\": 90\n",
      "    },\n",
      "    \"recipe_type\": \"dessert\",\n",
      "    \"necessary_utensils\": [\n",
      "        \"oven\",\n",
      "        \"springform_pan\",\n",
      "        \"bowl\",\n",
      "        \"serving_platter\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#check output\n",
    "out = pd.read_csv(\"output.csv\")\n",
    "first_item = out.iloc[0][\"content\"]\n",
    "dict_item = json.loads(first_item)\n",
    "from Schema import ExtractedData\n",
    "bericht = ExtractedData.model_validate(dict_item)\n",
    "print(json.dumps(dict_item, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check files in the workspace\n",
    "files = client.files.list()\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you may need to copy paste from above\n",
    "#input_file_ids = ['file-58ce5bda1e064389a411ee66b3455e1a', 'file-797a55b2da424b858e98163b7e71d946']\n",
    "\n",
    "\n",
    "# remove input files\n",
    "for file_id in input_file_ids:\n",
    "    client.files.delete(file_id)\n",
    "# remove output files\n",
    "for file_id in output_file_ids:\n",
    "    client.files.delete(file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all files ONLY RUN THIS IF YOU HAVE ASKED ALL OTHER USERS\n",
    "question = input(\"This delets all files from ALL users. Proceed? (yes/no)\")\n",
    "if question == \"yes\":\n",
    "    print(\"Deleting all files...\")\n",
    "\n",
    "    files = client.files.list()\n",
    "    for file in files:\n",
    "        client.files.delete(file.id)\n",
    "\n",
    "    # this btw. trows an error but still works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
